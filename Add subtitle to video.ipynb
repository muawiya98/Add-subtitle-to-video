{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sosano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import moviepy.editor as mp\n",
    "from googletrans import Translator, constants\n",
    "from pprint import pprint\n",
    "import speech_recognition as sr\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import PunktSentenceTokenizer\n",
    "from playsound import playsound\n",
    "from pydub import AudioSegment\n",
    "from moviepy.editor import *\n",
    "import arabic_reshaper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# قراءة الفيديو و تحويله إلى صوت "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translation(pathv):\n",
    "    clip = mp.VideoFileClip(pathv)\n",
    "    patha = pathv[0:pathv.find(\".\")]+\".wav\"\n",
    "    clip.audio.write_audiofile(patha)\n",
    "    return patha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# تقسيم الصوت إلى مقاطع صوتية أصغر"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SiplttingAudio(PathA,time):\n",
    "    ListOfPathAudio = []\n",
    "    time = time * 1000\n",
    "    print(PathA)\n",
    "    newAudio = AudioSegment.from_wav(PathA)\n",
    "    x = newAudio.duration_seconds * 1000 \n",
    "    count = 0\n",
    "    PathA = PathA[0:PathA.find(\".wav\")]\n",
    "    while(x>count):\n",
    "        t1 =  count\n",
    "        t2 =  time + count\n",
    "        newAudio1 = newAudio[t1:t2]\n",
    "        newAudio1.export(PathA+str(int(count/1000))+'.wav', format=\"wav\")\n",
    "        ListOfPathAudio.append(PathA+str(int(count/1000))+'.wav')\n",
    "        count = t2\n",
    "    return ListOfPathAudio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# تحويل التسيجلات الصوتية المقطعة إلى كلام "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SpeechToText(ListOfPathAudio):\n",
    "    ListText = []\n",
    "    r = sr.Recognizer()\n",
    "    for audio in ListOfPathAudio:\n",
    "        with sr.AudioFile(audio) as source:\n",
    "            audio_data = r.record(source)\n",
    "            text = r.recognize_google(audio_data)\n",
    "            ListText.append(text)\n",
    "    return ListText"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ترجمة الكلام في المقاطع الصوتية"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Transliation(ListText,lang):\n",
    "    ListOfText = []\n",
    "    translator = Translator()\n",
    "    for sent in ListText:\n",
    "        translations = translator.translate(sent, dest=lang)\n",
    "        ListOfText.append(translations.text)\n",
    "    return ListOfText\n",
    "#     for translation in translations:\n",
    "#         print(f\"{translation.origin} ({translation.src}) --> {translation.text} ({translation.dest})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# وضع الترجمة على الفيديو"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AddTextToVideo(pathv,ListOfText,ListText):\n",
    "    clip = VideoFileClip(pathv)\n",
    "    time = clip.duration\n",
    "    du = time/len(ListOfText)\n",
    "    clip = clip.volumex(0.5)\n",
    "    listy = []\n",
    "    listy.append(clip)\n",
    "    count = 0\n",
    "    tcount = time\n",
    "    n1 = 0\n",
    "    for n in ListOfText:\n",
    "        if(tcount>0):\n",
    "            txt_clip = TextClip(str(n+\"\\n\"+ListText[n1]), fontsize = 25, color = 'red')\n",
    "            txt_clip = txt_clip.set_pos('bottom').set_start(count).set_duration(du)\n",
    "            listy.append(txt_clip)\n",
    "            count+=du\n",
    "            tcount-=du\n",
    "            n1 = n1 + 1\n",
    "        else:\n",
    "            break\n",
    "    video = CompositeVideoClip(listy)\n",
    "    video.ipython_display(width = 280,maxduration = int(time*2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# التابع الرئيسي"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(pathv):\n",
    "    PathAudio = translation(pathv)\n",
    "    ListOfPathAudio = SiplttingAudio(PathAudio,5)\n",
    "    ListText = SpeechToText(ListOfPathAudio[100:200])\n",
    "    return ListText\n",
    "#     ListOfText = Transliation(ListText,'fr')\n",
    "#     AddTextToVideo(pathv,ListOfText,ListText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ListText = main(\"E:\\\\Graduation Project\\\\New folder\\\\stereo_file.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "chunk:   0%|                                                            | 29/146107 [00:00<14:14, 171.02it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in E:\\Graduation Project\\DataSetFP\\01.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "E:\\Graduation Project\\DataSetFP\\01.wav\n"
     ]
    },
    {
     "ename": "UnknownValueError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownValueError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-66976382405d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"C:\\\\Users\\\\user\\\\Desktop\\\\tete\\\\test.mp4\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mpathv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"E:\\\\Graduation Project\\\\DataSetFP\\\\01.France v Argentina - 2018 FIFA World Cup - Full Match.mp4\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpathv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-38-e57cc7d65dd7>\u001b[0m in \u001b[0;36mmain\u001b[1;34m(pathv)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mPathAudio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtranslation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpathv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mListOfPathAudio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSiplttingAudio\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPathAudio\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mListText\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSpeechToText\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mListOfPathAudio\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mListText\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#     ListOfText = Transliation(ListText,'fr')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-32-bf4a42c74c0e>\u001b[0m in \u001b[0;36mSpeechToText\u001b[1;34m(ListOfPathAudio)\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0msr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAudioFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maudio\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msource\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m             \u001b[0maudio_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m             \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecognize_google\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maudio_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m             \u001b[0mListText\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mListText\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\speech_recognition\\__init__.py\u001b[0m in \u001b[0;36mrecognize_google\u001b[1;34m(self, audio_data, key, language, show_all)\u001b[0m\n\u001b[0;32m    856\u001b[0m         \u001b[1;31m# return results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mshow_all\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[0mactual_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 858\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactual_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactual_result\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"alternative\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mraise\u001b[0m \u001b[0mUnknownValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    859\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    860\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m\"confidence\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mactual_result\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"alternative\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnknownValueError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pathv = \"C:\\\\Users\\\\user\\\\Desktop\\\\New folder\\\\test.mp4\"\n",
    "path = \"C:\\\\Users\\\\user\\\\Desktop\\\\tete\\\\test.mp4\"\n",
    "pathv = \"E:\\\\Graduation Project\\\\DataSetFP\\\\01.France v Argentina - 2018 FIFA World Cup - Full Match.mp4\"\n",
    "nn = main(pathv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ﺫﻫﺐ ﺍﻟﻄﺎﻟﺐ ﺍﻟﻰ ﺍﻟﻤﺪﺭﺳﺔ'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# install: pip install --upgrade arabic-reshaper\n",
    "import arabic_reshaper\n",
    "\n",
    "# install: pip install python-bidi\n",
    "# from bidi.algorithm import get_display\n",
    "\n",
    "text = \"ذهب الطالب الى المدرسة\"\n",
    "reshaped_text = arabic_reshaper.reshape(text)    # correct its shape\n",
    "# bidi_text = get_display(reshaped_text)    # correct its direction\n",
    "reshaped_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arabic_reshaper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathv = \"C:\\\\Users\\\\user\\\\Desktop\\\\New folder\\\\test.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "ListOfText = [\n",
    "    \"قيادة سيارة كارل لمعرفة مكان وجود السيارات والمشاة الآخرين حول هذا الأمر لصبي.\",\n",
    "    \"يجعل التعرف على الوجوه يعمل بشكل أفضل بكثير من أي وقت مضى\" ,\n",
    "    \"حتى يعرف البعض منكم قريبًا أنه قادر بالفعل على فتح هاتف\" ,\n",
    "    \"افتح الباب باستخدام وجهك فقط وإذا نظرت إلى هاتفك الخلوي\" ,\n",
    "    \"هاتفك المحمول يحصلون على العديد من التطبيقات التي تعرض لك صورًا للطعام أو مجرد متعة\" ,\n",
    "    \"صور المناظر الطبيعية ويستخدمها بعض منشئي الكمبيوتر\" ,\n",
    "    \"أنا أستخدم مجمل أعرض لكم الأجمل والأجمل والأكثر\" ,\n",
    "    \"الصور الأكثر صلة وأعتقد أنها تتيح لك الكتابة\" ,\n",
    "    \"هل يمكنك إنشاء نوع من الفن لذلك أعتقد أن السببين\" ,\n",
    "    \"سببان أنا متحمس لأن Evelyn e4y تعتقد أنك قد تكون أيضًا كذلك\" ,\n",
    "    \"التقدم السريع الأول في رؤية الكمبيوتر\" ,\n",
    "    \"تمكّن التطبيقات الجديدة تمامًا من أن تصبح سمكة ذهبية مستحيلة في السنوات القليلة الماضية\" ,\n",
    "    \"قبل بضع سنوات وتحت هذين الاثنين منكم سيكون قادرًا على التكثيف\" ,\n",
    "    \"ضع مسافة بادئة لبعض هذه المنتجات والتطبيقات الجديدة ثانيًا حتى لو لم تفعل ذلك\" ,\n",
    "    \"حتى لو لم ينتهي بك الأمر إلى إنشاء أنظمة رؤية الكمبيوتر ، لنفترض أنني وجدت ذلك بسبب\" ,\n",
    "    \"لأن مجتمع أبحاث رؤية الكمبيوتر ليس مبدعًا ومكثفًا جدًا\" ,\n",
    "    \"قم بعمل مكثف وابتكار الجديد وأنت وهذا هو مصدر إلهام لك\" ,\n",
    "    \"الإلهام كما لو كان دخول المستشفى في مناطق أخرى أيضًا\" ,\n",
    "    \"حسنًا ، يعمل تطبيق FaceTime لنظام التشغيل Windows على التعرف على الكلام ، أحيانًا ما استلهمت مني الإلهام من\" ,\n",
    "    \"المدة من الأفكار من رؤية الكمبيوتر واستعارةها بلا كلام\" ,\n",
    "    \"حتى لو لم ينتهي بك الأمر بالعمل حتى القسم ، آمل أن تجد أفكارًا لشخص ما\" ,\n",
    "    \"بعض الأفكار لك\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "chunk:   0%|                                                                        | 0/1883 [00:00<?, ?it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video __temp__.mp4.\n",
      "MoviePy - Writing audio in __temp__TEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:   0%|                                                                            | 0/2562 [00:00<?, ?it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video __temp__.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready __temp__.mp4\n"
     ]
    }
   ],
   "source": [
    "AddTextToVideo(pathv,ListOfText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"driving Carl's figure out where the other cars and pedestrians around this to it's a boy.\", \n",
    "'is making face recognition work much better than ever',\n",
    "\"so that perhaps some of you will soon know that's already be able to unlock a phone\",\n",
    "'unlock door using just your face and if you look on your cell phone',\n",
    "'your cell phone that they get many apps that show you pictures of food or just fun',\n",
    "'pictures of scenery and some of the computer builders are using',\n",
    "'I using the whole show you the most attractive the most beautiful or the most',\n",
    "'the most relevant pictures and I think even enabling you type', \n",
    "'can you type of art to be created so I think the two reasons',\n",
    "\"2 Reasons I'm excited about Evelyn e4y think you might be too\", \n",
    "'first rapid advances in computer vision', \"are enabling brand new applications to be a goldfish's impossible few years\", \n",
    "'few years ago and underneath these two of you will be able to condense', \n",
    "\"indent some of these new products and applications second even if you don't\", \n",
    "\"even if you don't end up building computer vision systems for say I found that because\", \n",
    "\"because the computer vision research Community hasn't so creative and so intensive\", \n",
    "\"do intensive and coming up with new and you and that's exactly inspire\", \n",
    "\"Inspire like it's locked hospitalization into other areas as well\", \n",
    "'well FaceTime for Windows work on speech recognition I sometimes that she took inspiration from my', \n",
    "'duration from ideas from computer vision and borrow them speechless',\n",
    "\"even if you don't end up working till Division I hope that you find somebody ideas\",\n",
    "'some of the ideas you.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AddTextToVideo(pathv,ListOfText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"قيادة سيارة كارل لمعرفة مكان وجود السيارات والمشاة الآخرين حول هذا الأمر لصبي.\"،\n",
    "\"يجعل التعرف على الوجوه يعمل بشكل أفضل بكثير من أي وقت مضى\" ،\n",
    "\"حتى يعرف البعض منكم قريبًا أنه قادر بالفعل على فتح هاتف\" ،\n",
    "\"افتح الباب باستخدام وجهك فقط وإذا نظرت إلى هاتفك الخلوي\" ،\n",
    "\"هاتفك المحمول يحصلون على العديد من التطبيقات التي تعرض لك صورًا للطعام أو مجرد متعة\" ،\n",
    "\"صور المناظر الطبيعية ويستخدمها بعض منشئي الكمبيوتر\" ،\n",
    "\"أنا أستخدم مجمل أعرض لكم الأجمل والأجمل والأكثر\" ،\n",
    "\"الصور الأكثر صلة وأعتقد أنها تتيح لك الكتابة\" ،\n",
    "\"هل يمكنك إنشاء نوع من الفن لذلك أعتقد أن السببين\" ،\n",
    "\"سببان أنا متحمس لأن Evelyn e4y تعتقد أنك قد تكون أيضًا كذلك\" ،\n",
    "\"التقدم السريع الأول في رؤية الكمبيوتر\" ، \"تمكّن التطبيقات الجديدة تمامًا من أن تصبح سمكة ذهبية مستحيلة في السنوات القليلة الماضية\" ،\n",
    "\"قبل بضع سنوات وتحت هذين الاثنين منكم سيكون قادرًا على التكثيف\" ،\n",
    "\"ضع مسافة بادئة لبعض هذه المنتجات والتطبيقات الجديدة ثانيًا حتى لو لم تفعل ذلك\" ،\n",
    "\"حتى لو لم ينتهي بك الأمر إلى إنشاء أنظمة رؤية الكمبيوتر ، لنفترض أنني وجدت ذلك بسبب\" ،\n",
    "\"لأن مجتمع أبحاث رؤية الكمبيوتر ليس مبدعًا ومكثفًا جدًا\" ،\n",
    "\"قم بعمل مكثف وابتكار الجديد وأنت وهذا هو مصدر إلهام لك\" ،\n",
    "\"الإلهام كما لو كان دخول المستشفى في مناطق أخرى أيضًا\" ،\n",
    "\"حسنًا ، يعمل تطبيق FaceTime لنظام التشغيل Windows على التعرف على الكلام ، أحيانًا ما استلهمت مني الإلهام من\" ،\n",
    "\"المدة من الأفكار من رؤية الكمبيوتر واستعارةها بلا كلام\" ،\n",
    "\"حتى لو لم ينتهي بك الأمر بالعمل حتى القسم ، آمل أن تجد أفكارًا لشخص ما\" ،\n",
    "\"بعض الأفكار لك\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# تحت أكواد تجريبية ما مهمين"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # translate more than a phrase\n",
    "# sentences = [\n",
    "#     \"Hello everyone\",\n",
    "#     \"How are you ?\",\n",
    "#     \"Do you speak english ?\",\n",
    "#     \"Good bye!\"\n",
    "# ]\n",
    "# translations = translator.translate(sentences, dest=\"ar\")\n",
    "# for translation in translations:\n",
    "#     print(f\"{translation.origin} ({translation.src}) --> {translation.text} ({translation.dest})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# playsound(\"1600720594318.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read MP3 file\n",
    "# song = AudioSegment.from_mp3(\"audio_file.mp3\")\n",
    "# song = AudioSegment.from_wav(\"1600720594318.wav\")\n",
    "# you can also read from other formats such as MP4\n",
    "# song = AudioSegment.from_file(\"1600720594318.mp4\", \"mp4\")\n",
    "# play(song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from moviepy.editor import VideoFileClip\n",
    "# clip = VideoFileClip(\"C:\\\\Users\\\\user\\\\Desktop\\\\C4W1L01 Computer Vision.mp4\")\n",
    "# print(clip.duration)\n",
    "# print(int(clip.duration+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Import everything needed to edit video clips\n",
    "# from moviepy.editor import *\n",
    "\n",
    "# # loading video dsa gfg intro video\n",
    "# clip = VideoFileClip(\"I'm Me.mp4\")\n",
    "\n",
    "# # clipping of the video\n",
    "# # getting video for only starting 10 seconds\n",
    "# clip = clip.subclip(0, 10)\n",
    "\n",
    "# # Reduce the audio volume (volume x 0.8)\n",
    "# clip = clip.volumex(0.8)\n",
    "\n",
    "# # Generate a text clip\n",
    "# txt_clip = TextClip(\"GeeksforGeeks\", fontsize = 75, color = 'black')\n",
    "\n",
    "# # setting position of text in the center and duration will be 10 seconds\n",
    "# txt_clip = txt_clip.set_pos('center').set_duration(10)\n",
    "\n",
    "# # Overlay the text clip on the first video clip\n",
    "# video = CompositeVideoClip([clip, txt_clip])\n",
    "\n",
    "# # showing video\n",
    "# video.ipython_display(width = 280)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from moviepy.editor import *\n",
    "# def AddTextToVideo(pathv,ListOfText):\n",
    "#     clip = VideoFileClip(pathv)\n",
    "#     time = clip.duration\n",
    "#     du = time/len(ListOfText)\n",
    "#     clip = clip.volumex(0.5)\n",
    "#     listy = []\n",
    "#     listy.append(clip)\n",
    "#     count = 0\n",
    "#     tcount = time\n",
    "#     for n in ListOfText:\n",
    "#         if(tcount>0):\n",
    "#             txt_clip = TextClip(n, fontsize = 25, color = 'red')\n",
    "#             txt_clip = txt_clip.set_pos('bottom').set_start(count).set_duration(du)\n",
    "#             listy.append(txt_clip)\n",
    "#             count+=du\n",
    "#             tcount-=du\n",
    "#         else:\n",
    "#             break\n",
    "#     video = CompositeVideoClip(listy)\n",
    "#     video.ipython_display(width = 280,maxduration = int(time*2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_list = ['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','W','X','Y','Z']\n",
    "# my_list =[\"I am me\",\n",
    "#           \"I will never pretend to be another\",\n",
    "#           \"I will never want to be another\",\n",
    "#           \"I will not change who I am just to finish\",\n",
    "#           \"I am me\",\n",
    "#           \"I am not perfect but\",\n",
    "#           \"But I'm working on myself\",\n",
    "#           \"working to become the best version of myself\",\n",
    "#           \"to continue to expend my own self\",\n",
    "#           \"through my own work\",\n",
    "#           \"in my own way\",\n",
    "#           \"I am me\",\n",
    "#           \"Not the me you think I am\",\n",
    "#           \"Not the me you want me to be\",\n",
    "#           \"but just me the one i want to be\",\n",
    "#           \"I am me\",\n",
    "#           \"I make my own decisions\",\n",
    "#           \"I don't follow\",\n",
    "#           \"I walk my own path\",\n",
    "#           \"It is not always easy\",\n",
    "#           \"But I'd rather walk a lone\",\n",
    "#           \"Than walk with others in the worng direction\",\n",
    "#           \"I am me\",\n",
    "#           \"I am strong\",\n",
    "#           \"I have a big heart\",\n",
    "#           \"I speak my truth\",\n",
    "#           \"I don't back down\",\n",
    "#           \"I am me\"]\n",
    "# # pathv = \"C:\\\\Users\\\\user\\\\Desktop\\\\C4W1L01 Computer Vision.mp4\"\n",
    "# pathv = \"I'm Me.mp4\"\n",
    "# pathv = \"Only.mp4\"\n",
    "# AddTextToVideo(pathv,my_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import moviepy.editor as mp\n",
    "# my_video = mp.VideoFileClip(\"I'm Me.mp4\", audio=True)\n",
    "# w,h = moviesize = my_video.size\n",
    "# my_text = mp.TextClip(\"The Art of Adding Text on Video\", font='Amiri-regular', color='white', fontsize=34)\n",
    "# txt_col = my_text.on_color(size=(my_video.w + my_text.w, my_text.h+5), color=(0,0,0), pos=(6,'center'), col_opacity=0.6)\n",
    "# txt_mov = txt_col.set_pos( lambda t: (max(w/30,int(w-0.5*w*t)),max(5*h/6,int(100*t))) )\n",
    "# final = mp.CompositeVideoClip([my_video,txt_mov])\n",
    "# final.ipython_display(width = 280)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # importing editor from movie py\n",
    "# from moviepy.editor import *\n",
    "\n",
    "# # text\n",
    "# text = \"GeeksforGeeks\"\n",
    "\n",
    "# # creating a text clip\n",
    "# # having font arial-bold\n",
    "# # with font size = 70\n",
    "# # and color = green\n",
    "# clip = TextClip(text, font =\"Arial-Bold\", fontsize = 70, color =\"green\")\n",
    "\n",
    "# # showing clip\n",
    "# clip.ipython_display()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pydub import AudioSegment\n",
    "# import math\n",
    "\n",
    "# class SplitWavAudioMubin():\n",
    "#     def __init__(self, folder, filename):\n",
    "#         self.folder = folder\n",
    "#         self.filename = filename\n",
    "#         self.filepath = folder + '\\\\' + filename\n",
    "        \n",
    "#         self.audio = AudioSegment.from_wav(self.filepath)\n",
    "    \n",
    "#     def get_duration(self):\n",
    "#         return self.audio.duration_seconds\n",
    "    \n",
    "#     def single_split(self, from_min, to_min, split_filename):\n",
    "#         t1 = from_min * 60 * 1000\n",
    "#         t2 = to_min * 60 * 1000\n",
    "#         split_audio = self.audio[t1:t2]\n",
    "#         split_audio.export(self.folder + '\\\\' + split_filename, format=\"wav\")\n",
    "        \n",
    "#     def multiple_split(self, min_per_split):\n",
    "#         total_mins = math.ceil(self.get_duration() / 60)\n",
    "#         for i in range(0, total_mins, min_per_split):\n",
    "#             split_fn = str(i) + '_' + self.filename\n",
    "#             self.single_split(i, i+min_per_split, split_fn)\n",
    "#             print(str(i) + ' Done')\n",
    "#             if i == total_mins - min_per_split:\n",
    "#                 print('All splited successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder = 'C:\\\\Users\\\\user\\\\Desktop'\n",
    "# file = 'Only.wav'\n",
    "# split_wav = SplitWavAudioMubin(folder, file)\n",
    "# split_wav.multiple_split(min_per_split=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = 'C:\\\\Users\\\\user\\\\Desktop\\\\memo\\\\Only.wav'\n",
    "# SiplttingAudio(path,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import wave\n",
    "# import math\n",
    "\n",
    "# def main(filename, time):\n",
    "#     read = wave.open(filename, 'r')\n",
    "#     print(1)\n",
    "\n",
    "# #get sample rate\n",
    "#     frameRate = read.getframerate()\n",
    "#     print(2)\n",
    "\n",
    "# #get number of frames\n",
    "#     numFrames = read.getnframes()\n",
    "#     print(3)\n",
    "\n",
    "# #get duration\n",
    "#     duration = numFrames/frameRate\n",
    "#     print(4)\n",
    "\n",
    "# #get all frames as a string of bytes\n",
    "#     frames = read.readframes(numFrames)\n",
    "#     print(5)\n",
    "\n",
    "# #get 1 frame as a string of bytes\n",
    "#     oneFrame = read.readframes(1)\n",
    "#     print(6)\n",
    "\n",
    "# #framerate*time == numframesneeded\n",
    "#     numFramesNeeded=frameRate*time\n",
    "#     print(7)\n",
    "\n",
    "# #numFramesNeeded*oneFrame=numBytes\n",
    "#     numBytes = numFramesNeeded*oneFrame\n",
    "#     print(8)\n",
    "\n",
    "# #splice frames to get a list strings each representing a 'time' length\n",
    "# #wav file\n",
    "#     x=0\n",
    "#     wavList=[]\n",
    "#     while x+time<=duration:\n",
    "#         curFrame= frames[x:x+time]\n",
    "#         x=x+time\n",
    "#         wavList.append(curFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main(\"C:\\\\Users\\\\user\\\\Desktop\\\\Only.wav\",1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pydub import AudioSegment\n",
    "# from pydub.silence import split_on_silence\n",
    "\n",
    "# sound_file = AudioSegment.from_wav(\"C:\\\\Users\\\\user\\\\Desktop\\\\Only.wav\")\n",
    "# audio_chunks = split_on_silence(sound_file, \n",
    "#     # must be silent for at least half a second\n",
    "#     min_silence_len=300,\n",
    "\n",
    "#     # consider it silent if quieter than -16 dBFS\n",
    "#     silence_thresh=-16)\n",
    "# for i, chunk in enumerate(audio_chunks):\n",
    "#     out_file = \"C:\\\\Users\\\\user\\\\Desktop\\\\memo\\\\chunk{0}.wav\".format(i)\n",
    "#     print(\"exporting\", out_file)\n",
    "#     chunk.export(out_file, format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extracted_from_sr_recognize_ibm(audio_data, username='IBM_USERNAME', password='IBM_PASSWORD', language=\"en-US\", show_all=False, timestamps=False,\n",
    "#                                 word_confidence=False, word_alternatives_threshold=0.1):\n",
    "#     assert isinstance(username, str), \"``username`` must be a string\"\n",
    "#     assert isinstance(password, str), \"``password`` must be a string\"\n",
    "\n",
    "#     flac_data = audio_data.get_flac_data(\n",
    "#         convert_rate=None if audio_data.sample_rate >= 16000 else 16000,  # audio samples should be at least 16 kHz\n",
    "#         convert_width=None if audio_data.sample_width >= 2 else 2  # audio samples should be at least 16-bit\n",
    "#     )\n",
    "#     url = \"https://stream-fra.watsonplatform.net/speech-to-text/api/v1/recognize?{}\".format(urlencode({\n",
    "#         \"profanity_filter\": \"false\",\n",
    "#         \"continuous\": \"true\",\n",
    "#         \"model\": \"{}_BroadbandModel\".format(language),\n",
    "#         \"timestamps\": \"{}\".format(str(timestamps).lower()),\n",
    "#         \"word_confidence\": \"{}\".format(str(word_confidence).lower()),\n",
    "#         \"word_alternatives_threshold\": \"{}\".format(word_alternatives_threshold)\n",
    "#     }))\n",
    "#     request = Request(url, data=flac_data, headers={\n",
    "#         \"Content-Type\": \"audio/x-flac\",\n",
    "#         \"X-Watson-Learning-Opt-Out\": \"true\",  # prevent requests from being logged, for improved privacy\n",
    "#     })\n",
    "#     authorization_value = base64.standard_b64encode(\"{}:{}\".format(username, password).encode(\"utf-8\")).decode(\"utf-8\")\n",
    "#     request.add_header(\"Authorization\", \"Basic {}\".format(authorization_value))\n",
    "\n",
    "#     try:\n",
    "#         response = urlopen(request, timeout=None)\n",
    "#     except HTTPError as e:\n",
    "#         raise sr.RequestError(\"recognition request failed: {}\".format(e.reason))\n",
    "#     except URLError as e:\n",
    "#         raise sr.RequestError(\"recognition connection failed: {}\".format(e.reason))\n",
    "#     response_text = response.read().decode(\"utf-8\")\n",
    "#     result = json.loads(response_text)\n",
    "\n",
    "#     # return results\n",
    "#     if show_all: return result\n",
    "#     if \"results\" not in result or len(result[\"results\"]) < 1 or \"alternatives\" not in result[\"results\"][0]:\n",
    "#         raise Exception(\"Unknown Value Exception\")\n",
    "\n",
    "#     transcription = []\n",
    "#     for utterance in result[\"results\"]:\n",
    "#         if \"alternatives\" not in utterance:\n",
    "#             raise Exception(\"Unknown Value Exception. No Alternatives returned\")\n",
    "#         for hypothesis in utterance[\"alternatives\"]:\n",
    "#             if \"transcript\" in hypothesis:\n",
    "#                 transcription.append(hypothesis[\"transcript\"])\n",
    "#     return \"\\n\".join(transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sound_file = AudioSegment.from_wav(\"C:\\\\Users\\\\user\\\\Desktop\\\\Only.wav\")\n",
    "# extracted_from_sr_recognize_ibm(sound_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
